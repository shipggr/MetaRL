{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from a2c.model import Model\n",
    "from a2c.runner import Runner\n",
    "import tensorflow as tf\n",
    "from bandits import *\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import scipy.signal\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model \"agent_test\":\n",
      "  \"agent_test\" was trained for 327000 epochs, using 26160000 timesteps\n",
      "  \"agent_test\" has following parameters: lr = 0.000500\n"
     ]
    }
   ],
   "source": [
    "model_config = {'scope' : 'agent_test', 'lstm_units' : 12, \n",
    "                'gamma' : 0.5, 'ent_coef' : 0.05, 'vf_coef' : 0.5,\n",
    "                'max_grad_norm' : 50,  \n",
    "                'lr' : 5e-4, 'lr_half_period' : 1500000, 'anneal_lr' : False, \n",
    "                'path': './experiments/12unitsmodel/'}\n",
    "\n",
    "nactions = 2\n",
    "nobs = 4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "train_bandits = [second_order_bandit(P_intervals = [(0.01, 0.99)]),\n",
    "                 first_order_bandit(P_intervals = [(0.01, 0.99)]),\n",
    "                 zero_order_bandit(P_intervals = [(0.01, 0.99)])]\n",
    "\n",
    "model = Model(nactions, nobs, sess = sess, **model_config)\n",
    "model.load_model()\n",
    "\n",
    "runner = Runner(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Savinig model after 500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 1000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 1500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 2000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 2500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 3000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 3500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 4000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 4500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 5000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 5500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 6000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 6500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 7000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 7500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 8000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 8500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 9000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 9500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 10000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 10500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 11000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 11500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 12000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 12500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 13000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 13500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 14000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 14500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 15000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 15500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 16000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 16500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 17000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 17500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 18000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 18500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 19000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 19500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 20000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 20500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 21000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 21500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 22000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 22500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 23000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 23500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 24000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 24500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 25000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 25500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 26000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 26500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 27000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 27500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 28000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 28500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 29000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 29500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 30000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 30500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 31000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 31500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 32000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 32500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 33000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 33500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 34000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 34500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 35000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 35500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 36000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 36500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 37000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 37500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 38000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 38500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 39000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 39500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 40000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 40500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 41000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 41500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 42000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 42500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 43000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 43500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 44000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 44500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 45000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 45500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 46000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 46500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 47000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 47500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 48000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 48500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 49000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 49500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Savinig model after 50000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 50500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 51000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 51500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 52000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 52500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 53000 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 53500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 54000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 54500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 55000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 55500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 56000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 56500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 57000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 57500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 58000 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 58500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 59000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 59500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 60000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 60500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 61000 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 61500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 62000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 62500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 63000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 63500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 64000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 64500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 65000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 65500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 66000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 66500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 67000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 67500 episodes of training\n",
      "Average env speed is 2.2 ep/second\n",
      "\n",
      "Savinig model after 68000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 68500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 69000 episodes of training\n",
      "Average env speed is 2.3 ep/second\n",
      "\n",
      "Savinig model after 69500 episodes of training\n",
      "Average env speed is 2.3 ep/second\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-75d424f7e249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bandits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/MetaRL/Remake/a2c/runner.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(self, neps, bandits, save_summary_every, save_model_every)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbandit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbandits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_summary_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MetaRL/Remake/a2c/runner.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0madvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mploss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Losses/Policy Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mploss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Losses/Value Loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MetaRL/Remake/a2c/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, obs, actions, values, returns, advs, inp_state)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         ploss, vloss, entloss, _ = self.sess.run([self.policy_loss, self.value_loss, self.entropy, self._train],\n\u001b[0;32m--> 102\u001b[0;31m                                                  feed_dict)\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training, not necessary if model was loaded\n",
    "runner.run_training(1000000, train_bandits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Humans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load subjects' data and create bandits for earch subject condition pair\n",
    "\n",
    "path_to_data = './data/' \n",
    "good_subjects = [3,4,5,6,8,9,10,11,12,13,14,15,17,18,19,20,21,22,23,24,28,29,30,31,\n",
    "                 32,33,34,35,36,37,38,39,40,41]\n",
    "\n",
    "good_subjects = [str(s) for s in good_subjects]\n",
    "\n",
    "actions_sub = defaultdict(dict)\n",
    "obses_sub = defaultdict(dict)\n",
    "rewards_sub = defaultdict(dict)\n",
    "test_bandits = []\n",
    "\n",
    "for cond in ['1', '2', '3', '4']:\n",
    "    for sub in good_subjects:\n",
    "        \n",
    "        path = path_to_data + 'Subject%s_Cond%s_behavior.txt' % (sub, cond)\n",
    "        \n",
    "        data = np.loadtxt(path, dtype = 'int')\n",
    "        data[:, :2] = data[:, :2] - 1\n",
    "        \n",
    "        actions_sub['Subject%sCond%s' % (sub, cond)] = data[:, 0]\n",
    "        obses_sub['Subject%sCond%s' % (sub, cond)] = data[:, 1]\n",
    "        rewards_sub['Subject%sCond%s' % (sub, cond)] = data[:, 2]\n",
    "        \n",
    "        bandit = determenistic_bandit(data[:, 1])\n",
    "        bandit.name = 'Subject%sCond%s' % (sub, cond)\n",
    "        test_bandits.append(bandit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running model on the humans data\n",
    "rewards, stats = runner.run_evaluation(1, test_bandits)\n",
    "subject_keys = stats.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing each unit in lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01,  0.01,  0.06],\n",
       "       [-0.02, -0.09,  0.04],\n",
       "       [ 0.08, -0.75, -0.26],\n",
       "       [-0.05, -0.25, -0.2 ],\n",
       "       [ 0.29, -0.02,  0.27],\n",
       "       [ 0.12, -0.01,  0.42],\n",
       "       [-0.02,  0.01,  0.02],\n",
       "       [-0.15, -0.52,  0.14],\n",
       "       [-0.25,  0.28, -0.57],\n",
       "       [ 0.05, -0.21,  0.09],\n",
       "       [-0.02,  0.2 , -0.25],\n",
       "       [-0.06, -0.13, -0.02]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing spearman rank correlation for each unit's activity with rewards at t, t-1, t-2\n",
    "\n",
    "# for outputs\n",
    "\n",
    "correlations  = []\n",
    "for comp in range(12):\n",
    "    corr_list = []\n",
    "    for k in subject_keys:\n",
    "        outputs = np.array(stats[k]['lstm_outputs'])[0, :, 0, 0, comp]\n",
    "        outputs_sc = (outputs - np.min(outputs)) / (np.max(outputs) - np.min(outputs))\n",
    "        \n",
    "        corr_0 = spearmanr(outputs_sc, obses_sub[k])[0]\n",
    "        corr_1 = spearmanr(outputs_sc[1:], obses_sub[k][:-1])[0]\n",
    "        corr_2 = spearmanr(outputs_sc[2:], obses_sub[k][:-2])[0]\n",
    "        corr_list.append((corr_0, corr_1, corr_2))\n",
    "        \n",
    "    correlations.append(np.mean(corr_list, 0))\n",
    "    \n",
    "correlations = np.round(correlations, 2)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01,  0.02,  0.06],\n",
       "       [-0.01, -0.08,  0.06],\n",
       "       [ 0.08, -0.75, -0.28],\n",
       "       [-0.05, -0.26, -0.21],\n",
       "       [ 0.12,  0.49,  0.06],\n",
       "       [ 0.08, -0.19,  0.47],\n",
       "       [-0.  , -0.  ,  0.  ],\n",
       "       [-0.13, -0.27, -0.31],\n",
       "       [-0.2 ,  0.14, -0.58],\n",
       "       [ 0.05, -0.07,  0.14],\n",
       "       [-0.02,  0.03,  0.07],\n",
       "       [ 0.  ,  0.  ,  0.01]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing spearman rank correlation for each unit's activity with rewards at t, t-1, t-2\n",
    "correlations_states  = []\n",
    "for comp in range(12):\n",
    "    corr_list = []\n",
    "    for k in subject_keys:\n",
    "        states = np.array(stats[k]['lstm_states'])[0, :, 0, 0, comp]\n",
    "        states_sc = (states - np.min(states)) / (np.max(states) - np.min(states))\n",
    "        \n",
    "        corr_0 = spearmanr(states_sc, obses_sub[k])[0]\n",
    "        corr_1 = spearmanr(states_sc[1:], obses_sub[k][:-1])[0]\n",
    "        corr_2 = spearmanr(states_sc[2:], obses_sub[k][:-2])[0]\n",
    "        corr_list.append((corr_0, corr_1, corr_2))\n",
    "        \n",
    "    correlations_states.append(np.mean(corr_list, 0))\n",
    "    \n",
    "correlations_states = np.round(correlations_states, 2)\n",
    "correlations_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp 0, best th 0.4, scores [0.53 0.55 0.53]\n",
      "Comp 1, best th 0.3, scores [0.54 0.55 0.54]\n",
      "Comp 2, best th 0.3, scores [0.66 0.88 0.71]\n",
      "Comp 3, best th 0.5, scores [0.56 0.6  0.58]\n",
      "Comp 4, best th 0.6, scores [0.64 0.71 0.73]\n",
      "Comp 5, best th 0.4, scores [0.61 0.62 0.72]\n",
      "Comp 6, best th 0.2, scores [0.53 0.53 0.54]\n",
      "Comp 7, best th 0.3, scores [0.63 0.75 0.7 ]\n",
      "Comp 8, best th 0.5, scores [0.64 0.72 0.77]\n",
      "Comp 9, best th 0.2, scores [0.55 0.57 0.56]\n",
      "Comp 10, best th 0.2, scores [0.56 0.55 0.6 ]\n",
      "Comp 11, best th 0.5, scores [0.53 0.54 0.53]\n"
     ]
    }
   ],
   "source": [
    "# same as above, but instead correlation, checking how similar is the binarized unit's activity \n",
    "# to reward at t, t-1, t-2\n",
    "scores = defaultdict(dict)\n",
    "for comp in range(12):\n",
    "    for th in [0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "        scores_list = []\n",
    "        for k in subject_keys:\n",
    "            \n",
    "            outputs = np.array(stats[k]['lstm_outputs'])[0, :, 0, 0, comp]\n",
    "            outputs_sc = (outputs - np.min(outputs)) / (np.max(outputs) - np.min(outputs))\n",
    "\n",
    "            outputs_bin = np.zeros(outputs_sc.shape, dtype = 'int')\n",
    "            outputs_bin[outputs_sc <= th] = 1\n",
    "            \n",
    "            score_0 = max(np.mean(outputs_bin == obses_sub[k]), 1 - np.mean(outputs_bin == obses_sub[k]))\n",
    "            \n",
    "            score_1 = max(np.mean(outputs_bin[1:] == obses_sub[k][:-1]), \n",
    "                          1 - np.mean(outputs_bin[1:] == obses_sub[k][:-1])) \n",
    "            \n",
    "            score_2 = max(np.mean(outputs_bin[2:] == obses_sub[k][:-2]),\n",
    "                          1 - np.mean(outputs_bin[2:] == obses_sub[k][:-2]))\n",
    "            \n",
    "            scores_list.append((score_0, score_1, score_2))\n",
    "        scores[comp][th] = np.round(np.mean(scores_list, 0), 2)\n",
    "        \n",
    "for comp in scores:\n",
    "    keys = list(scores[comp].keys())\n",
    "    ths_scores = [np.max(scores[comp][th]) for th in keys]\n",
    "    best_th = keys[np.argmax(ths_scores)]\n",
    "    print('Comp %d, best th %.1f, scores' % (comp, best_th), scores[comp][best_th] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comp 0, best th 0.5, scores [0.54 0.56 0.55]\n",
      "Comp 1, best th 0.3, scores [0.54 0.55 0.54]\n",
      "Comp 2, best th 0.4, scores [0.66 0.82 0.73]\n",
      "Comp 3, best th 0.5, scores [0.56 0.6  0.58]\n",
      "Comp 4, best th 0.6, scores [0.6  0.73 0.7 ]\n",
      "Comp 5, best th 0.5, scores [0.61 0.66 0.73]\n",
      "Comp 6, best th 0.4, scores [0.56 0.56 0.56]\n",
      "Comp 7, best th 0.5, scores [0.59 0.63 0.64]\n",
      "Comp 8, best th 0.5, scores [0.64 0.71 0.8 ]\n",
      "Comp 9, best th 0.4, scores [0.55 0.58 0.57]\n",
      "Comp 10, best th 0.3, scores [0.54 0.54 0.54]\n",
      "Comp 11, best th 0.5, scores [0.56 0.56 0.56]\n"
     ]
    }
   ],
   "source": [
    "# same as above, but instead correlation, checking how similar is the binarized unit's activity \n",
    "# to reward at t, t-1, t-2\n",
    "scores = defaultdict(dict)\n",
    "for comp in range(12):\n",
    "    for th in [0.2, 0.3, 0.4, 0.5, 0.6]:\n",
    "        scores_list = []\n",
    "        for k in subject_keys:\n",
    "            \n",
    "            states = np.array(stats[k]['lstm_states'])[0, :, 0, 0, comp]\n",
    "            states_sc = (states - np.min(states)) / (np.max(states) - np.min(states))\n",
    "\n",
    "            states_bin = np.zeros(states_sc.shape, dtype = 'int')\n",
    "            states_bin[states_sc <= th] = 1\n",
    "            \n",
    "            score_0 = max(np.mean(states_bin == obses_sub[k]), 1 - np.mean(states_bin == obses_sub[k]))\n",
    "            \n",
    "            score_1 = max(np.mean(states_bin[1:] == obses_sub[k][:-1]), \n",
    "                          1 - np.mean(states_bin[1:] == obses_sub[k][:-1])) \n",
    "            \n",
    "            score_2 = max(np.mean(states_bin[2:] == obses_sub[k][:-2]),\n",
    "                          1 - np.mean(states_bin[2:] == obses_sub[k][:-2]))\n",
    "            \n",
    "            scores_list.append((score_0, score_1, score_2))\n",
    "        scores[comp][th] = np.round(np.mean(scores_list, 0), 2)\n",
    "        \n",
    "for comp in scores:\n",
    "    keys = list(scores[comp].keys())\n",
    "    ths_scores = [np.max(scores[comp][th]) for th in keys]\n",
    "    best_th = keys[np.argmax(ths_scores)]\n",
    "    print('Comp %d, best th %.1f, scores' % (comp, best_th), scores[comp][best_th] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
